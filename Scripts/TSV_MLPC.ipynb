{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "905ddd20-2dde-4dc8-99a8-f0c3fe4d032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9b1e10-33f3-4b05-a346-49f1680fd471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5fc1d82-51a2-45c5-bf20-cec1a06b00b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rips(maxdim=1, thresh=inf, coeff=2, do_cocycles=False, n_perm = None, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, matthews_corrcoef, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from Element_PI_JC import VariancePersist_JC\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde58a15-8275-4bed-a6a4-accca4ea88ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model results have been saved.\n"
     ]
    }
   ],
   "source": [
    "# Set up constants\n",
    "receptor = 'GCR'\n",
    "\n",
    "# Bayesian TPI Hyperparameters \n",
    "pixel = 21\n",
    "myspread = 0.06\n",
    "\n",
    "# MLPC Epochs\n",
    "num_epochs = 300\n",
    "\n",
    "# Load SMILES strings\n",
    "def load_smiles(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return [line.strip() for line in f]\n",
    "\n",
    "# Define MLPC Architecture\n",
    "class MLPC(nn.Module):\n",
    "    def __init__(self, input_size, seed=20):\n",
    "        super(MLPC, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(300, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(150, 75),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(75, 2),\n",
    "        )\n",
    "        self._initialize_weights(seed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _initialize_weights(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        for layer in self.model:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "\n",
    "# Generate Persistence Images\n",
    "def generate_persistence_images(xyz_files, pixelx, pixely, spread, myspecs):\n",
    "    TT_manual = []\n",
    "    for cmp in xyz_files:\n",
    "        TT_image = VariancePersist_JC(cmp, pixelx=pixelx, pixely=pixely, myspread=spread, myspecs=myspecs, showplot=False)\n",
    "        TT_manual.append(TT_image.flatten())\n",
    "    return np.array(TT_manual)\n",
    "\n",
    "# Function to compute MACCS keys\n",
    "def get_maccs_keys(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return np.array(AllChem.GetMACCSKeysFingerprint(mol))\n",
    "\n",
    "# Load data\n",
    "train_test_files = sorted(glob.glob(f'{receptor}_*.xyz'))\n",
    "validation_files = sorted(glob.glob(f'Validation/{receptor}_*.xyz'))\n",
    "train_test_labels_df = pd.read_excel(f'{receptor}_MLinput.xlsx', header=None)\n",
    "validation_labels_df = pd.read_excel(f'Validation/{receptor}_Validation.xlsx', header=None)\n",
    "\n",
    "labels_train_test = train_test_labels_df.iloc[:, 1].values\n",
    "labels_validation = validation_labels_df.iloc[:, 1].values\n",
    "\n",
    "train_test_smiles = load_smiles(f'{receptor}_TT_SMILES.smi')\n",
    "validation_smiles = load_smiles(f'Validation/{receptor}_V_SMILES.smi')\n",
    "\n",
    "def train_and_evaluate():\n",
    "    # Load data\n",
    "    pixelx, pixely, spread, myspecs = pixel, pixel, myspread, {\"maxBD\": 2.5, \"minBD\": -0.1}\n",
    "    train_test_pi = generate_persistence_images(train_test_files, pixelx, pixely, myspread, myspecs)\n",
    "    validation_pi = generate_persistence_images(validation_files, pixelx, pixely, myspread, myspecs)\n",
    "\n",
    "    train_test_maccs = np.array([get_maccs_keys(smiles) for smiles in train_test_smiles])\n",
    "    validation_maccs = np.array([get_maccs_keys(smiles) for smiles in validation_smiles])\n",
    "\n",
    "    # Define scaler lists for grid search\n",
    "    maccs_scalers = [0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00, 3.25, 3.50, 3.75, 4.00]\n",
    "    pi_scalers = [0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00, 3.25, 3.50, 3.75, 4.00]\n",
    "    # Initialize variables for grid search\n",
    "    best_validation_mcc = -np.inf\n",
    "    best_hyperparameters = None\n",
    "    best_fold_metrics = []\n",
    "    best_loss_data = []\n",
    "    best_auc_data = []\n",
    "    best_validation_metrics = {}\n",
    "\n",
    "    for maccs_scaler in maccs_scalers:\n",
    "        for pi_scaler in pi_scalers:\n",
    "            #print(f\"Testing MACCS scaler: {maccs_scaler}, PI scaler: {pi_scaler}\")\n",
    "            \n",
    "            # Apply scalers to description vectors\n",
    "            scaled_train_test_maccs = train_test_maccs * maccs_scaler\n",
    "            scaled_validation_maccs = validation_maccs * maccs_scaler\n",
    "            scaled_train_test_pi = train_test_pi * pi_scaler\n",
    "            scaled_validation_pi = validation_pi * pi_scaler\n",
    "\n",
    "            train_test_data = np.hstack([scaled_train_test_pi, scaled_train_test_maccs])\n",
    "            validation_data = np.hstack([scaled_validation_pi, scaled_validation_maccs])\n",
    "\n",
    "            skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "            smote = SMOTE(random_state=42)\n",
    "\n",
    "            fold_metrics = []\n",
    "            loss_data = []\n",
    "            auc_data = []\n",
    "\n",
    "            for fold_idx, (train_idx, test_idx) in enumerate(skf.split(train_test_data, labels_train_test)):\n",
    "                X_train, X_test = train_test_data[train_idx], train_test_data[test_idx]\n",
    "                y_train, y_test = labels_train_test[train_idx], labels_train_test[test_idx]\n",
    "\n",
    "                X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "                X_train_tensor = torch.tensor(X_train_smote, dtype=torch.float32)\n",
    "                y_train_tensor = torch.tensor(y_train_smote, dtype=torch.long)\n",
    "                X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "                y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "                model = MLPC(input_size=X_train_tensor.shape[1], seed=20)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "                train_losses = []\n",
    "                test_losses = []\n",
    "\n",
    "                for epoch in range(num_epochs):\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    train_outputs = model(X_train_tensor)\n",
    "                    train_loss = criterion(train_outputs, y_train_tensor)\n",
    "                    train_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    train_losses.append(train_loss.item())\n",
    "\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        test_outputs = model(X_test_tensor)\n",
    "                        test_loss = criterion(test_outputs, y_test_tensor)\n",
    "                        test_losses.append(test_loss.item())\n",
    "\n",
    "                loss_data.extend([{\"Fold\": fold_idx + 1, \"Epoch\": e + 1, \"Dataset\": \"Training\", \"Loss\": train_losses[e]} \n",
    "                                  for e in range(num_epochs)] +\n",
    "                                 [{\"Fold\": fold_idx + 1, \"Epoch\": e + 1, \"Dataset\": \"Testing\", \"Loss\": test_losses[e]} \n",
    "                                  for e in range(num_epochs)])\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    train_outputs = model(X_train_tensor)\n",
    "                    train_preds = torch.argmax(train_outputs, dim=1).numpy()\n",
    "                    train_probs = torch.softmax(train_outputs, dim=1)[:, 1].numpy()\n",
    "                    train_acc = accuracy_score(y_train_smote, train_preds)\n",
    "                    train_bal_acc = balanced_accuracy_score(y_train_smote, train_preds)\n",
    "                    train_mcc = matthews_corrcoef(y_train_smote, train_preds)\n",
    "                    train_auc = roc_auc_score(y_train_smote, train_probs)\n",
    "\n",
    "                    test_outputs = model(X_test_tensor)\n",
    "                    test_preds = torch.argmax(test_outputs, dim=1).numpy()\n",
    "                    test_probs = torch.softmax(test_outputs, dim=1)[:, 1].numpy()\n",
    "                    test_acc = accuracy_score(y_test, test_preds)\n",
    "                    test_bal_acc = balanced_accuracy_score(y_test, test_preds)\n",
    "                    test_mcc = matthews_corrcoef(y_test, test_preds)\n",
    "                    test_auc = roc_auc_score(y_test, test_probs)\n",
    "\n",
    "                fold_metrics.append({\n",
    "                    \"Fold\": fold_idx + 1,\n",
    "                    \"Train Accuracy\": train_acc, \"Train Balanced Accuracy\": train_bal_acc,\n",
    "                    \"Train MCC\": train_mcc, \"Train AUC\": train_auc,\n",
    "                    \"Test Accuracy\": test_acc, \"Test Balanced Accuracy\": test_bal_acc,\n",
    "                    \"Test MCC\": test_mcc, \"Test AUC\": test_auc\n",
    "                })\n",
    "\n",
    "                fpr_train, tpr_train, thresholds_train = roc_curve(y_train_smote, train_probs)\n",
    "                fpr_test, tpr_test, thresholds_test = roc_curve(y_test, test_probs)\n",
    "                auc_data.extend([\n",
    "                    {\"Fold\": fold_idx + 1, \"Dataset\": \"Training\", \"FPR\": f, \"TPR\": t, \"Threshold\": th}\n",
    "                    for f, t, th in zip(fpr_train, tpr_train, thresholds_train)\n",
    "                ] + [\n",
    "                    {\"Fold\": fold_idx + 1, \"Dataset\": \"Testing\", \"FPR\": f, \"TPR\": t, \"Threshold\": th}\n",
    "                    for f, t, th in zip(fpr_test, tpr_test, thresholds_test)\n",
    "                ])\n",
    "\n",
    "            validation_tensor = torch.tensor(validation_data, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                validation_outputs = model(validation_tensor)\n",
    "                validation_preds = torch.argmax(validation_outputs, dim=1).numpy()\n",
    "                validation_probs = torch.softmax(validation_outputs, dim=1)[:, 1].numpy()\n",
    "                val_acc = accuracy_score(labels_validation, validation_preds)\n",
    "                val_bal_acc = balanced_accuracy_score(labels_validation, validation_preds)\n",
    "                val_mcc = matthews_corrcoef(labels_validation, validation_preds)\n",
    "                val_auc = roc_auc_score(labels_validation, validation_probs)\n",
    "\n",
    "                validation_metrics = {\n",
    "                    \"Accuracy\": val_acc, \"Balanced Accuracy\": val_bal_acc,\n",
    "                    \"MCC\": val_mcc, \"AUC\": val_auc\n",
    "                }\n",
    "\n",
    "            if validation_metrics[\"MCC\"] > best_validation_mcc:\n",
    "                best_validation_mcc = validation_metrics[\"MCC\"]\n",
    "                best_hyperparameters = {\"MACCS Scaler\": maccs_scaler, \"PI Scaler\": pi_scaler}\n",
    "                best_fold_metrics = fold_metrics\n",
    "                best_loss_data = loss_data\n",
    "                best_auc_data = auc_data\n",
    "                best_validation_metrics = validation_metrics\n",
    "\n",
    "    # Save results to CSV files\n",
    "    pd.DataFrame(best_fold_metrics).to_csv(f\"{receptor}_TSV_best_fold_metrics.csv\", index=False)\n",
    "    pd.DataFrame(best_loss_data).to_csv(f\"{receptor}_TSV_best_loss_data.csv\", index=False)\n",
    "    pd.DataFrame(best_auc_data).to_csv(f\"{receptor}_TSV_best_auc_data.csv\", index=False)\n",
    "    pd.DataFrame([best_hyperparameters]).to_csv(f\"{receptor}_TSV_best_hyperparameters.csv\", index=False)\n",
    "    pd.DataFrame([best_validation_metrics]).to_csv(f\"{receptor}_TSV_best_validation_metrics.csv\", index=False)\n",
    "\n",
    "    print(\"Best model results have been saved.\")\n",
    "\n",
    "train_and_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
