{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ee42b2-0664-42ff-8682-e03de8ce4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25745dbe-7e2c-4250-a703-132d25a1a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5127c6d-f744-4c7b-acec-5975c2d1d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, matthews_corrcoef, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2222cf24-c816-4455-9b8f-6a0b38f0f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "receptor = 'GCR'\n",
    "train_test_smiles = load_smiles(f'{receptor}_TT_SMILES.smi')\n",
    "validation_smiles = load_smiles(f'Validation/{receptor}_V_SMILES.smi')\n",
    "train_test_labels_df = pd.read_excel(f'{receptor}_MLinput.xlsx', header=None)\n",
    "validation_labels_df = pd.read_excel(f'Validation/{receptor}_Validation.xlsx', header=None)\n",
    "\n",
    "labels_train_test = train_test_labels_df.iloc[:, 1].values\n",
    "labels_validation = validation_labels_df.iloc[:, 1].values\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RS = 42 # StratifiedKfold and SMOTE seed\n",
    "nn_seed = 20 # MLPC seed\n",
    "\n",
    "# Load SMILES strings\n",
    "def load_smiles(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        smiles_list = [line.strip() for line in file]\n",
    "    return smiles_list\n",
    "\n",
    "# Calculate MACCS Keys\n",
    "def calculate_maccs_keys(smiles_list):\n",
    "    maccs_keys = []\n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:\n",
    "            maccs = MACCSkeys.GenMACCSKeys(mol)\n",
    "            maccs_keys.append(np.array(maccs))\n",
    "        else:\n",
    "            maccs_keys.append(np.zeros(166))\n",
    "            print('SMILES error, check .smi file')\n",
    "    return np.array(maccs_keys)\n",
    "\n",
    "# Define MLPC Architecture\n",
    "class MLPC(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPC, self).__init__()\n",
    "        torch.manual_seed(nn_seed)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 300), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(300, 150), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(150, 75), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(75, 2)\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        torch.manual_seed(nn_seed)\n",
    "        for layer in self.model:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "\n",
    "# Calculate MACCS Keys\n",
    "maccs_keys_train_test = calculate_maccs_keys(train_test_smiles)\n",
    "maccs_keys_validation = calculate_maccs_keys(validation_smiles)\n",
    "\n",
    "# Training and evaluation\n",
    "def train_and_evaluate(X, y, X_val, y_val, num_folds=10):\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=RS)\n",
    "    smote = SMOTE(random_state=RS)\n",
    "\n",
    "    # Containers for metrics, losses, and AUC data\n",
    "    fold_metrics = []\n",
    "    epoch_losses = []\n",
    "    auc_data = []\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Handle class imbalance\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "        # Initialize model, loss function, optimizer\n",
    "        model = MLPC(input_size=X.shape[1])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "        # Train the model\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        for epoch in range(300):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            train_outputs = model(X_train_tensor)\n",
    "            train_loss = criterion(train_outputs, y_train_tensor)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(train_loss.item())\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_outputs = model(X_test_tensor)\n",
    "                test_loss = criterion(test_outputs, y_test_tensor)\n",
    "                test_losses.append(test_loss.item())\n",
    "\n",
    "        epoch_losses.extend(\n",
    "            [{\"Fold\": fold_idx + 1, \"Epoch\": e + 1, \"Dataset\": \"Training\", \"Loss\": train_losses[e]} for e in range(300)] +\n",
    "            [{\"Fold\": fold_idx + 1, \"Epoch\": e + 1, \"Dataset\": \"Testing\", \"Loss\": test_losses[e]} for e in range(300)]\n",
    "        )\n",
    "\n",
    "        # Evaluate on training and testing sets\n",
    "        with torch.no_grad():\n",
    "            train_probs = nn.Softmax(dim=1)(model(X_train_tensor)).numpy()[:, 1]\n",
    "            test_probs = nn.Softmax(dim=1)(model(X_test_tensor)).numpy()[:, 1]\n",
    "            train_preds = torch.argmax(model(X_train_tensor), dim=1).numpy()\n",
    "            test_preds = torch.argmax(model(X_test_tensor), dim=1).numpy()\n",
    "\n",
    "        fold_metrics.append({\n",
    "            \"Fold\": fold_idx + 1,\n",
    "            \"Train Accuracy\": accuracy_score(y_train, train_preds),\n",
    "            \"Train Balanced Accuracy\": balanced_accuracy_score(y_train, train_preds),\n",
    "            \"Train MCC\": matthews_corrcoef(y_train, train_preds),\n",
    "            \"Train AUC\": roc_auc_score(y_train, train_probs),\n",
    "            \"Test Accuracy\": accuracy_score(y_test, test_preds),\n",
    "            \"Test Balanced Accuracy\": balanced_accuracy_score(y_test, test_preds),\n",
    "            \"Test MCC\": matthews_corrcoef(y_test, test_preds),\n",
    "            \"Test AUC\": roc_auc_score(y_test, test_probs),\n",
    "        })\n",
    "\n",
    "        # Save AUC data for ROC curves\n",
    "        fpr_train, tpr_train, thresholds_train = roc_curve(y_train, train_probs)\n",
    "        fpr_test, tpr_test, thresholds_test = roc_curve(y_test, test_probs)\n",
    "        auc_data.extend([\n",
    "            {\"Fold\": fold_idx + 1, \"Dataset\": \"Training\", \"FPR\": fpr, \"TPR\": tpr, \"Threshold\": th}\n",
    "            for fpr, tpr, th in zip(fpr_train, tpr_train, thresholds_train)\n",
    "        ] + [\n",
    "            {\"Fold\": fold_idx + 1, \"Dataset\": \"Testing\", \"FPR\": fpr, \"TPR\": tpr, \"Threshold\": th}\n",
    "            for fpr, tpr, th in zip(fpr_test, tpr_test, thresholds_test)\n",
    "        ])\n",
    "\n",
    "    # Validation metrics\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        val_probs = nn.Softmax(dim=1)(model(X_val_tensor)).numpy()[:, 1]\n",
    "        val_preds = torch.argmax(model(X_val_tensor), dim=1).numpy()\n",
    "\n",
    "    validation_metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_val, val_preds),\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(y_val, val_preds),\n",
    "        \"MCC\": matthews_corrcoef(y_val, val_preds),\n",
    "        \"AUC\": roc_auc_score(y_val, val_probs),\n",
    "    }\n",
    "\n",
    "    # Save results to CSV files\n",
    "    pd.DataFrame(fold_metrics).to_csv(f\"{receptor}_MACCS_best_model_fold_metrics.csv\", index=False)\n",
    "    pd.DataFrame(epoch_losses).to_csv(f\"{receptor}_MACCS_epoch_losses.csv\", index=False)\n",
    "    pd.DataFrame(auc_data).to_csv(f\"{receptor}_MACCS_auc_data.csv\", index=False)\n",
    "    pd.DataFrame([validation_metrics]).to_csv(f\"{receptor}_MACCS_validation_metrics.csv\", index=False)\n",
    "\n",
    "    return None\n",
    "\n",
    "# Run training and evaluation\n",
    "train_and_evaluate(maccs_keys_train_test, labels_train_test, maccs_keys_validation, labels_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60dfc5c-f0dd-4ec6-92ea-b706ec529e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
