{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09f32e0-5617-4e52-8e43-37207441e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ddb18a-99a5-4c5f-ad86-e7cf1a495b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "443007b7-ec2e-4c71-b601-4de1e5fa3878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rips(maxdim=1, thresh=inf, coeff=2, do_cocycles=False, n_perm = None, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, label_binarize\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, balanced_accuracy_score, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from Element_PI_JC import VariancePersist_JC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee93548-4406-4ced-b958-9e5b065fd758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model results saved to CSV Flipped_PI files.\n"
     ]
    }
   ],
   "source": [
    "# File paths and configurations\n",
    "receptor = 'GCR'\n",
    "\n",
    "train_test_files = sorted(glob.glob(f'{receptor}_*.xyz'))\n",
    "validation_files = sorted(glob.glob(f'Validation/{receptor}_*.xyz'))\n",
    "train_test_labels_df = pd.read_excel(f'{receptor}_MLinput.xlsx', header=None)\n",
    "validation_labels_df = pd.read_excel(f'Validation/{receptor}_Validation.xlsx', header=None)\n",
    "\n",
    "labels_train_test = train_test_labels_df.iloc[:, 1].values\n",
    "labels_validation = validation_labels_df.iloc[:, 1].values\n",
    "\n",
    "# TPI Hyperparameter Ranges for Grid Search\n",
    "pixelx_range = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "spread_range = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10]\n",
    "myspecs = {\"maxBD\": 2.5, \"minBD\": -0.1}\n",
    "\n",
    "# MLPC hyperparameters\n",
    "RS = 42 # Random seed for StratifiedKfold and SMOTE\n",
    "nn_seed = 20 # MPLC weight for reprodicibility\n",
    "epochs = 300 # MLPC epochs\n",
    "learning = 0.001 # MLPC learning rate\n",
    "decay = 1e-5 # MLPC L2 regularization\n",
    "\n",
    "# Track the best model\n",
    "best_mcc = -np.inf\n",
    "best_model_info = {\n",
    "    \"fold_metrics\": [],\n",
    "    \"epoch_losses\": [],\n",
    "    \"validation_results\": {},\n",
    "    \"auc_data\": [],\n",
    "    \"hyperparameters\": {}\n",
    "}\n",
    "\n",
    "# Define MLPC\n",
    "class MLPC(nn.Module):\n",
    "    def __init__(self, input_size, seed=nn_seed):\n",
    "        super(MLPC, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 300), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(300, 150),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(150, 75), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(75, 2),\n",
    "        )\n",
    "        self._initialize_weights(seed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    def _initialize_weights(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        for layer in self.model:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    init.zeros_(layer.bias)\n",
    "\n",
    "# Generate Persistence Images\n",
    "def generate_reduced_persistence_images(xyz_files, pixelx, pixely, spread, myspecs):\n",
    "    TT_manual = []\n",
    "    for cmp in xyz_files:\n",
    "        TT_image = VariancePersist_JC(cmp, pixelx=pixelx, pixely=pixely, myspread=spread, myspecs=myspecs, showplot=False)\n",
    "        TT_manual.append(TT_image)\n",
    "    return np.array(TT_manual)\n",
    "\n",
    "# Main Grid Search\n",
    "for pixelx in pixelx_range:\n",
    "    pixely = pixelx\n",
    "    for myspread in spread_range:\n",
    "        train_test_features = generate_reduced_persistence_images(train_test_files, pixelx, pixely, myspread, myspecs)\n",
    "        validation_features = generate_reduced_persistence_images(validation_files, pixelx, pixely, myspread, myspecs)\n",
    "        smote = SMOTE(random_state=RS)\n",
    "        train_test_features_resampled, labels_train_test_resampled = smote.fit_resample(train_test_features, labels_train_test)\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=RS)\n",
    "        \n",
    "        fold_metrics = []\n",
    "        epoch_losses = []\n",
    "        auc_data = []\n",
    "\n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(skf.split(train_test_features_resampled, labels_train_test_resampled)):\n",
    "            X_train, X_test = train_test_features_resampled[train_idx], train_test_features_resampled[test_idx]\n",
    "            y_train, y_test = labels_train_test_resampled[train_idx], labels_train_test_resampled[test_idx]\n",
    "            X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "            y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "            X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "            y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "            model = MLPC(input_size=X_train_tensor.shape[1])\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = Adam(model.parameters(), lr=learning, weight_decay=decay)\n",
    "\n",
    "            train_losses = []\n",
    "            test_losses = []\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                train_outputs = model(X_train_tensor)\n",
    "                train_loss = criterion(train_outputs, y_train_tensor)\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(train_loss.item())\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    test_outputs = model(X_test_tensor)\n",
    "                    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "                    test_losses.append(test_loss.item())\n",
    "\n",
    "            epoch_losses.extend(\n",
    "                [{\"Fold\": fold_idx + 1, \"Epoch\": e + 1, \"Dataset\": \"Training\", \"Loss\": train_losses[e]} for e in range(epochs)] +\n",
    "                [{\"Fold\": fold_idx + 1, \"Epoch\": e + 1, \"Dataset\": \"Testing\", \"Loss\": test_losses[e]} for e in range(epochs)]\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                train_probs = nn.Softmax(dim=1)(model(X_train_tensor)).numpy()[:, 1]\n",
    "                test_probs = nn.Softmax(dim=1)(model(X_test_tensor)).numpy()[:, 1]\n",
    "                train_pred = torch.max(model(X_train_tensor), 1)[1].numpy()\n",
    "                test_pred = torch.max(model(X_test_tensor), 1)[1].numpy()\n",
    "\n",
    "            avg_train_metrics = {\n",
    "                \"Accuracy\": accuracy_score(y_train, train_pred),\n",
    "                \"Balanced Accuracy\": balanced_accuracy_score(y_train, train_pred),\n",
    "                \"MCC\": matthews_corrcoef(y_train, train_pred),\n",
    "                \"AUC\": roc_auc_score(label_binarize(y_train, classes=[0, 1]), train_probs),\n",
    "            }\n",
    "\n",
    "            test_metrics = {\n",
    "                \"Accuracy\": accuracy_score(y_test, test_pred),\n",
    "                \"Balanced Accuracy\": balanced_accuracy_score(y_test, test_pred),\n",
    "                \"MCC\": matthews_corrcoef(y_test, test_pred),\n",
    "                \"AUC\": roc_auc_score(label_binarize(y_test, classes=[0, 1]), test_probs),\n",
    "            }\n",
    "\n",
    "            fold_metrics.append({\n",
    "                \"Fold\": fold_idx + 1,\n",
    "                **{f\"Train {k}\": v for k, v in avg_train_metrics.items()},\n",
    "                **{f\"Test {k}\": v for k, v in test_metrics.items()},\n",
    "            })\n",
    "\n",
    "            # Log AUC data for ROC curves\n",
    "            fpr_train, tpr_train, thresholds_train = roc_curve(label_binarize(y_train, classes=[0, 1]), train_probs)\n",
    "            fpr_test, tpr_test, thresholds_test = roc_curve(label_binarize(y_test, classes=[0, 1]), test_probs)\n",
    "            auc_data.extend([\n",
    "                {\"Fold\": fold_idx + 1, \"Dataset\": \"Training\", \"FPR\": fpr, \"TPR\": tpr, \"Threshold\": th}\n",
    "                for fpr, tpr, th in zip(fpr_train, tpr_train, thresholds_train)\n",
    "            ] + [\n",
    "                {\"Fold\": fold_idx + 1, \"Dataset\": \"Testing\", \"FPR\": fpr, \"TPR\": tpr, \"Threshold\": th}\n",
    "                for fpr, tpr, th in zip(fpr_test, tpr_test, thresholds_test)\n",
    "            ])\n",
    "\n",
    "        validation_tensor = torch.tensor(validation_features, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            validation_outputs = model(validation_tensor)\n",
    "            validation_probs = nn.Softmax(dim=1)(validation_outputs).numpy()[:, 1]\n",
    "            validation_pred = torch.max(validation_outputs, 1)[1].numpy()\n",
    "\n",
    "            validation_metrics = {\n",
    "                \"Accuracy\": accuracy_score(labels_validation, validation_pred),\n",
    "                \"Balanced Accuracy\": balanced_accuracy_score(labels_validation, validation_pred),\n",
    "                \"MCC\": matthews_corrcoef(labels_validation, validation_pred),\n",
    "                \"AUC\": roc_auc_score(label_binarize(labels_validation, classes=[0, 1]), validation_probs)\n",
    "            }\n",
    "\n",
    "        if validation_metrics[\"MCC\"] > best_mcc:\n",
    "            best_mcc = validation_metrics[\"MCC\"]\n",
    "            best_model_info[\"fold_metrics\"] = fold_metrics\n",
    "            best_model_info[\"epoch_losses\"] = epoch_losses\n",
    "            best_model_info[\"validation_results\"] = validation_metrics\n",
    "            best_model_info[\"auc_data\"] = auc_data\n",
    "            best_model_info[\"hyperparameters\"] = {\"pixelx\": pixelx, \"pixely\": pixely, \"spread\": myspread}\n",
    "\n",
    "# Save results for the best model\n",
    "pd.DataFrame(best_model_info[\"fold_metrics\"]).to_csv(f\"{receptor}_TPI_best_model_fold_metrics.csv\", index=False)\n",
    "pd.DataFrame(best_model_info[\"epoch_losses\"]).to_csv(f\"{receptor}_TPI_best_model_epoch_losses.csv\", index=False)\n",
    "pd.DataFrame([best_model_info[\"validation_results\"]]).to_csv(f\"{receptor}_TPI_best_model_validation_metrics.csv\", index=False)\n",
    "pd.DataFrame(best_model_info[\"auc_data\"]).to_csv(f\"{receptor}_TPI_best_model_auc_data.csv\", index=False)\n",
    "pd.DataFrame([best_model_info[\"hyperparameters\"]]).to_csv(f\"{receptor}_TPI_best_model_hyperparameters.csv\", index=False)\n",
    "\n",
    "print(\"Best model results saved to CSV Flipped_PI files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364759b6-2e3f-4e2d-a7a0-c0ed2758f16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
